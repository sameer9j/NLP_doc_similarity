{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Similarity\n",
    "\n",
    "#### The aim of the code is to check the document similarity using different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/sameer/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to convert the tag given by nltk.pos_tag to the tag used by wordnet.synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tag(tag):    \n",
    "    tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'}\n",
    "    try:\n",
    "        return tag_dict[tag[0]]\n",
    "    except KeyError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to return a list of synsets in document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_synsets(doc):\n",
    "    doc_t = nltk.word_tokenize(doc)\n",
    "    doc_t_pos = nltk.pos_tag(doc_t)\n",
    "    syn = [(w,convert_tag(t)) for w,t in doc_t_pos]\n",
    "    synt = [wn.synsets(s, pos = p) for s,p in syn]\n",
    "    snt_n = []\n",
    "    for s in synt:\n",
    "        if len(s)>0:\n",
    "            snt_n.append(s[0])\n",
    "        else:\n",
    "            snt_n.append(s)\n",
    "    return snt_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to calculate the normalized similarity score (using Path Similarity, and Wup Similarity) of s1 onto s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(s1, s2, meth = \"path_similarity\"):  \n",
    "    tot = []\n",
    "    for a in s1:\n",
    "        if a:\n",
    "            sc = []\n",
    "            for b in s2:\n",
    "                if b:\n",
    "                    if meth == \"path_similarity\":\n",
    "                        z = wn.path_similarity(a,b)\n",
    "                    elif meth == \"wup_similarity\":\n",
    "                        z = wn.wup_similarity(a,b)\n",
    "                        \n",
    "                    if z:\n",
    "                        sc.append(z)\n",
    "            if sc:\n",
    "                sc = sorted(sc,reverse=True)\n",
    "                tot.append(sc[0])\n",
    "    return sum(tot)/len(tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to find the symmetrical similarity between doc1 and doc2\n",
    "##### As the scores are not symmetrical, finding out the average score of (doc1, doc2) and (doc2, doc1) similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_path_similarity(doc1, doc2, meth = \"path_similarity\"):\n",
    "    synsets1 = doc_to_synsets(doc1)\n",
    "    synsets2 = doc_to_synsets(doc2)\n",
    "    return (similarity_score(synsets1, synsets2, meth) + similarity_score(synsets2, synsets1, meth)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function which tests the document path similarity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.554265873015873"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_document_path_similarity():\n",
    "    doc1 = 'This is a function to test document_path_similarity.'\n",
    "    doc2 = 'Use this function to see if your code in doc_to_synsets \\\n",
    "    and similarity_score is correct!'\n",
    "    return document_path_similarity(doc1, doc2)\n",
    "\n",
    "test_document_path_similarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputting dummy values to check the accuracy of the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"That is a cat\"\n",
    "doc2 = \"That is a dog\"\n",
    "doc3 = \"That is cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333334"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_path_similarity(doc1,doc2,'path_similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523809523809524"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_path_similarity(doc1,doc2,'wup_similarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can observe that the score with wup similarity is higher compared to path similarity, as Wu-Palmer Similarity returns a score denoting how similar two word senses are, based on the depth of the two senses in the taxonomy and that of their Least Common Subsumer (most specific ancestor node). Whereas, path similarity returns a score denoting how similar two word senses are, based on the shortest path that connects the senses in the is-a (hypernym/hypnoym) taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_path_similarity(doc1,doc3,'path_similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_path_similarity(doc1,doc3,'wup_similarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can observe that scores for doc1 and doc3 are 1.0, which is expected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
